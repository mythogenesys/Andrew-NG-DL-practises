{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "562d99c9-c74f-4806-9792-b6af5a1e6d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data'\n",
    "column_names = ['Age', 'Year', 'Nodes', 'Survival']\n",
    "data = pd.read_csv(url, header=None, names=column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "721a2818-294b-430d-8797-e1e238c4f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Encode the target variable (1 if survived 5 years or more, 0 otherwise)\n",
    "data['Survival'] = data['Survival'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop('Survival', axis=1).values\n",
    "Y = data['Survival'].values.reshape(1, -1)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y.T, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "382d097f-6169-461b-8a89-1fb866deed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train).T\n",
    "X_test = scaler.transform(X_test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44377059-3355-4b2e-83d9-9cf0738d46bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6931468084798695\n",
      "Cost after iteration 100: 0.6613357742699116\n",
      "Cost after iteration 200: 0.6394297737310929\n",
      "Cost after iteration 300: 0.6242695836476109\n",
      "Cost after iteration 400: 0.6137109262342252\n",
      "Cost after iteration 500: 0.6063072873772918\n",
      "Cost after iteration 600: 0.601081622597037\n",
      "Cost after iteration 700: 0.5973705308139625\n",
      "Cost after iteration 800: 0.5947203418978739\n",
      "Cost after iteration 900: 0.5928183674546107\n",
      "Cost after iteration 1000: 0.5914473899222962\n",
      "Cost after iteration 1100: 0.590455376362039\n",
      "Cost after iteration 1200: 0.5897351792168556\n",
      "Cost after iteration 1300: 0.5892108018237842\n",
      "Cost after iteration 1400: 0.58882804760922\n",
      "Cost after iteration 1500: 0.5885480611325041\n",
      "Cost after iteration 1600: 0.5883428662201309\n",
      "Cost after iteration 1700: 0.5881922414500574\n",
      "Cost after iteration 1800: 0.5880815194055236\n",
      "Cost after iteration 1900: 0.5880000305680647\n",
      "Cost after iteration 2000: 0.5879399963018557\n",
      "Cost after iteration 2100: 0.5878957279993522\n",
      "Cost after iteration 2200: 0.587863060050301\n",
      "Cost after iteration 2300: 0.5878389365002975\n",
      "Cost after iteration 2400: 0.5878211122064837\n",
      "Cost after iteration 2500: 0.5878079356385911\n",
      "Cost after iteration 2600: 0.5877981905834739\n",
      "Cost after iteration 2700: 0.5877909805860287\n",
      "Cost after iteration 2800: 0.5877856443005618\n",
      "Cost after iteration 2900: 0.5877816935374195\n",
      "Cost after iteration 3000: 0.5877787676655505\n",
      "Cost after iteration 3100: 0.587776600179432\n",
      "Cost after iteration 3200: 0.5877749940380214\n",
      "Cost after iteration 3300: 0.5877738034408254\n",
      "Cost after iteration 3400: 0.5877729205922758\n",
      "Cost after iteration 3500: 0.5877722656634097\n",
      "Cost after iteration 3600: 0.5877717795794654\n",
      "Cost after iteration 3700: 0.5877714185783876\n",
      "Cost after iteration 3800: 0.5877711502627112\n",
      "Cost after iteration 3900: 0.5877709506082551\n",
      "Cost after iteration 4000: 0.5877708018291775\n",
      "Cost after iteration 4100: 0.5877706907512508\n",
      "Cost after iteration 4200: 0.5877706076127326\n",
      "Cost after iteration 4300: 0.5877705451771197\n",
      "Cost after iteration 4400: 0.587770498084419\n",
      "Cost after iteration 4500: 0.5877704623595474\n",
      "Cost after iteration 4600: 0.587770435058689\n",
      "Cost after iteration 4700: 0.5877704139991898\n",
      "Cost after iteration 4800: 0.5877703974487946\n",
      "Cost after iteration 4900: 0.5877703843541382\n",
      "Cost after iteration 4999: 0.5877703738906284\n"
     ]
    }
   ],
   "source": [
    "from cleaned_nn import DeepNeuralNetwork\n",
    "\n",
    "# Define the layer dimensions (input layer size should match the number of features)\n",
    "layer_dims = [3, 5, 4, 1]  # Example architecture\n",
    "\n",
    "# Initialize and train the model\n",
    "model = DeepNeuralNetwork(layer_dims, learning_rate=0.0075, num_iterations=5000, print_cost=True)\n",
    "parameters, costs = model.fit(X_train, Y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08820df1-f01e-4474-8cbb-3e49ab1431d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7741935483870968\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Forward propagation on the test set\n",
    "AL_test, _ = model.L_model_forward(X_test)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "predictions = (AL_test > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predictions == Y_test)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "016d7cb1-87bf-410e-b773-ec6034a1ebd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 6.73988550883008\n",
      "Cost after iteration 100: 9.14914753234236\n",
      "Cost after iteration 200: 9.095285815240679\n",
      "Cost after iteration 300: 11.603848721000231\n",
      "Cost after iteration 400: 9.359517901588283\n",
      "Cost after iteration 500: 10.08942975217019\n",
      "Cost after iteration 600: 10.532440553469776\n",
      "Cost after iteration 700: 13.54213405166867\n",
      "Cost after iteration 800: 7.783563448476475\n",
      "Cost after iteration 900: 11.05139788227108\n",
      "Cost after iteration 1000: 12.678020803090847\n",
      "Cost after iteration 1100: 10.144294687650145\n",
      "Cost after iteration 1200: 10.512594722653159\n",
      "Cost after iteration 1300: 9.629033116610964\n",
      "Cost after iteration 1400: 10.624319059029213\n",
      "Cost after iteration 1500: 8.291483908039002\n",
      "Cost after iteration 1600: 9.625929361586351\n",
      "Cost after iteration 1700: 8.669839661172198\n",
      "Cost after iteration 1800: 9.741341201373581\n",
      "Cost after iteration 1900: 11.062544637872078\n",
      "Cost after iteration 2000: 10.889244432638439\n",
      "Cost after iteration 2100: 11.58655720666161\n",
      "Cost after iteration 2200: 9.347595998114063\n",
      "Cost after iteration 2300: 8.966554165961341\n",
      "Cost after iteration 2400: 12.038070155427834\n",
      "Cost after iteration 2500: 11.282876327698814\n",
      "Cost after iteration 2600: 10.527589426120173\n",
      "Cost after iteration 2700: 13.249962911271465\n",
      "Cost after iteration 2800: 10.354534530153353\n",
      "Cost after iteration 2900: 13.559463810633325\n",
      "Cost after iteration 3000: 10.676863079965594\n",
      "Cost after iteration 3100: 11.061221744854144\n",
      "Cost after iteration 3200: 9.891772588456552\n",
      "Cost after iteration 3300: 8.719344186412554\n",
      "Cost after iteration 3400: 9.225481511191694\n",
      "Cost after iteration 3500: 11.380892441597084\n",
      "Cost after iteration 3600: 11.036434236493445\n",
      "Cost after iteration 3700: 8.896733034793199\n",
      "Cost after iteration 3800: 8.273967392471292\n",
      "Cost after iteration 3900: 11.527955005746934\n",
      "Cost after iteration 4000: 12.743324338580539\n",
      "Cost after iteration 4100: 14.063495290321244\n",
      "Cost after iteration 4200: 9.522350055468916\n",
      "Cost after iteration 4300: 10.65559870776635\n",
      "Cost after iteration 4400: 9.427532308193618\n",
      "Cost after iteration 4500: 13.97840629392508\n",
      "Cost after iteration 4600: 12.95362873146032\n",
      "Cost after iteration 4700: 11.07134113880965\n",
      "Cost after iteration 4800: 9.57822172261116\n",
      "Cost after iteration 4900: 10.01503950166338\n",
      "Cost after iteration 5000: 11.979550854561996\n",
      "Cost after iteration 5100: 10.11044759211852\n",
      "Cost after iteration 5200: 12.69496606290839\n",
      "Cost after iteration 5300: 12.416019888376923\n",
      "Cost after iteration 5400: 12.025149161697266\n",
      "Cost after iteration 5500: 9.031243671741406\n",
      "Cost after iteration 5600: 11.122767682660161\n",
      "Cost after iteration 5700: 9.305419361108008\n",
      "Cost after iteration 5800: 11.589073828324404\n",
      "Cost after iteration 5900: 11.067542528195945\n",
      "Cost after iteration 6000: 11.740685792412211\n",
      "Cost after iteration 6100: 9.650006625599332\n",
      "Cost after iteration 6200: 11.608325632957635\n",
      "Cost after iteration 6300: 11.570919590074217\n",
      "Cost after iteration 6400: 11.574970083838664\n",
      "Cost after iteration 6500: 10.487935149653335\n",
      "Cost after iteration 6600: 12.902360306309815\n",
      "Cost after iteration 6700: 10.929909129266424\n",
      "Cost after iteration 6800: 10.487595641967703\n",
      "Cost after iteration 6900: 11.469965102963908\n",
      "Cost after iteration 7000: 8.69367857534286\n",
      "Cost after iteration 7100: 11.171690003424514\n",
      "Cost after iteration 7200: 10.555620661809726\n",
      "Cost after iteration 7300: 10.219432436517547\n",
      "Cost after iteration 7400: 9.320459708159625\n",
      "Cost after iteration 7500: 11.045741462895718\n",
      "Cost after iteration 7600: 10.226016837756303\n",
      "Cost after iteration 7700: 9.730723115390266\n",
      "Cost after iteration 7800: 12.681250035257694\n",
      "Cost after iteration 7900: 10.982385814278452\n",
      "Cost after iteration 8000: 9.812990341832032\n",
      "Cost after iteration 8100: 9.69684015126642\n",
      "Cost after iteration 8200: 12.42139104510129\n",
      "Cost after iteration 8300: 10.002288748824824\n",
      "Cost after iteration 8400: 9.20749995797304\n",
      "Cost after iteration 8500: 9.64732688343053\n",
      "Cost after iteration 8600: 9.632226805719087\n",
      "Cost after iteration 8700: 9.92497614889196\n",
      "Cost after iteration 8800: 12.168573241980496\n",
      "Cost after iteration 8900: 10.99037138312134\n",
      "Cost after iteration 9000: 11.061018523902561\n",
      "Cost after iteration 9100: 12.89227803796978\n",
      "Cost after iteration 9200: 13.039923790647226\n",
      "Cost after iteration 9300: 10.46173386545312\n",
      "Cost after iteration 9400: 10.624833096672534\n",
      "Cost after iteration 9500: 10.934193773704983\n",
      "Cost after iteration 9600: 11.018364678051558\n",
      "Cost after iteration 9700: 10.767474481914501\n",
      "Cost after iteration 9800: 11.378286642763019\n",
      "Cost after iteration 9900: 10.63223979965381\n",
      "Cost after iteration 9999: 9.86630487152525\n"
     ]
    }
   ],
   "source": [
    "from improved_clnn import DeepNeuralNetwork\n",
    "\n",
    "# Define the layer dimensions (input layer size should match the number of features)\n",
    "layer_dims = [3, 5, 4, 1] # Example architecture\n",
    "\n",
    "# Initialize and train the model\n",
    "model = DeepNeuralNetwork(layer_dims, learning_rate=0.0075, num_iterations=10000, print_cost=True)\n",
    "parameters, costs = model.fit(X_train, Y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690a9446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6149843912591051\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Forward propagation on the test set\n",
    "AL_test, _ = model.L_model_forward(X_test)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "predictions = (AL_test > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predictions == Y_test)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669950d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
